# VideoRAG ğŸ¥

**Intelligent Document & Video Q&A System using Retrieval-Augmented Generation**

VideoRAG is a powerful system that extracts content from videos (audio transcription + on-screen text OCR) and documents (PDF/PowerPoint) to enable semantic question-answering through advanced RAG technology.

## âœ¨ Features

- ğŸ¥ **Multi-Modal Video Processing**: Extract both audio (Whisper ASR) and visual text (EasyOCR)
- ğŸ“„ **Document Support**: Process PDF and PowerPoint files
- ğŸŒ **Web Interface**: User-friendly Streamlit UI with drag-and-drop uploads
- ğŸ”§ **Configurable Components**: Choose your embedding models, LLMs, vector databases, and chunking strategies
- ğŸ’¬ **Interactive Q&A**: Ask questions about your content with chat history
- ğŸ¯ **Timestamp-Aware**: Answers reference specific time ranges in videos
- ğŸš€ **Easy Setup**: One-click installation scripts for Windows

## ğŸš€ Quick Start

### 1. Setup Environment

```bash
# Run setup script (installs dependencies and creates virtual environment)
setup.bat
```

### 2. Launch Streamlit Web Interface (Recommended)

```bash
# Start the web application
run_streamlit.bat
```

The app will open automatically in your browser at `http://localhost:8501`

### 3. Use the Application

1. **Configure** (Sidebar):
   - Select Embedding Model (default: BGE Base)
   - Select LLM (default: Qwen 0.6B)
   - Select Vector Database (default: FAISS)
   - Select Chunking Strategy (default: Simple)
   - Click "Initialize RAG Pipeline"

2. **Upload** (Main Area):
   - Drag and drop your file (PDF, PPTX, or Video)
   - Click "Process & Index"
   - Wait for processing to complete

3. **Ask Questions**:
   - Type your question in the chat interface
   - Click "Ask"
   - Get AI-powered answers based on your content!

## ğŸ–¥ï¸ Alternative: Command Line Interface

```bash
# Interactive CLI mode
run.bat
# Or: python main.py

# Test different chunking strategies
python rag_library/test_chunkers.py
```

## ğŸ“‹ Requirements

### System Requirements
- **Python**: 3.8 or higher
- **FFmpeg**: Required for video/audio processing ([Download](https://ffmpeg.org/))
- **RAM**: 8GB+ recommended (16GB for large models)
- **Disk Space**: 5GB+ for models and dependencies

### Python Dependencies
All dependencies are installed automatically via `setup.bat`. Key packages include:
- `torch` - Deep learning framework
- `transformers` - HuggingFace models
- `sentence-transformers` - Embedding models
- `faiss-cpu` - Vector indexing
- `openai-whisper` - Audio transcription
- `easyocr` - OCR engine
- `streamlit` - Web interface
- `chromadb` - Alternative vector store

## ğŸ¯ Supported File Types

| Type | Extensions | Processing |
|------|-----------|------------|
| **Video** | `.mp4`, `.avi`, `.mov`, `.mkv` | Whisper ASR + EasyOCR |
| **PDF** | `.pdf` | PyMuPDF text extraction |
| **PowerPoint** | `.pptx`, `.ppt` | python-pptx extraction |

## ğŸ”§ Configuration Options

### Embedding Models
- **BGE Base** (Recommended) - Balanced performance
- **BGE Small** - Faster, less accurate
- **BGE Large** - More accurate, slower
- **MiniLM L6** - Lightweight option
- **MPNet Base** - General-purpose

### Language Models
- **Qwen 0.6B** (Default) - Fast, good quality
- **Qwen 1.8B** - Better quality, slower
- **Phi-2** - Microsoft model
- **TinyLlama** - Lightweight option

### Vector Databases
- **FAISS** (Recommended) - Fast, efficient
- **ChromaDB** - Persistent storage
- **In-Memory** - Fastest, no persistence

### Chunking Strategies
- **Simple Text Splitter** - Character-based chunking
- **Sentence Splitter** - Sentence boundary-aware
- **Semantic Chunker** - Similarity-based chunking
- **ASR Timestamp Chunker** - Time-windowed (for videos)

## ğŸ“‚ Project Structure

```
VideoRag/
â”œâ”€â”€ streamlit_app.py          # Web interface (main entry point)
â”œâ”€â”€ main.py                   # CLI interface
â”œâ”€â”€ setup.bat                 # Environment setup script
â”œâ”€â”€ run_streamlit.bat         # Launch web app
â”œâ”€â”€ run.bat                   # Launch CLI
â”œâ”€â”€ scripts/                  # Video processing pipeline
â”‚   â”œâ”€â”€ video_processor.py    # Main orchestrator
â”‚   â”œâ”€â”€ video_downloader.py   # YouTube/URL download
â”‚   â”œâ”€â”€ audio_extractor.py    # FFmpeg audio extraction
â”‚   â”œâ”€â”€ frame_extractor.py    # FFmpeg frame extraction
â”‚   â”œâ”€â”€ transcriber.py        # Whisper ASR
â”‚   â””â”€â”€ ocr_extractor.py      # EasyOCR
â”œâ”€â”€ rag_library/              # RAG framework
â”‚   â”œâ”€â”€ embeddings/           # Embedding models
â”‚   â”œâ”€â”€ llm/                  # Language models
â”‚   â”œâ”€â”€ vectordb/             # Vector databases
â”‚   â”œâ”€â”€ chuncking/            # Chunking strategies
â”‚   â”œâ”€â”€ retriever/            # Retrieval logic
â”‚   â”œâ”€â”€ pipeline/             # RAG orchestration
â”‚   â””â”€â”€ loaders/              # Document loaders
â”œâ”€â”€ videos/                   # Input videos
â”œâ”€â”€ extracted/                # Intermediate outputs
â”‚   â”œâ”€â”€ audio/
â”‚   â”œâ”€â”€ frames/
â”‚   â””â”€â”€ ocr/
â””â”€â”€ transcripts/              # Final JSON outputs
```

## ğŸ¬ How It Works

### For Videos:
1. **Extract Audio** â†’ Convert to WAV via FFmpeg
2. **Extract Frames** â†’ Sample frames at 1 FPS
3. **Transcribe** â†’ Whisper generates timestamped text
4. **OCR** â†’ EasyOCR extracts on-screen text
5. **Merge** â†’ Combine ASR + OCR into segments
6. **Chunk** â†’ Split into time windows (default: 15s)
7. **Embed** â†’ Convert to vectors
8. **Index** â†’ Store in FAISS/ChromaDB
9. **Query** â†’ Retrieve relevant chunks â†’ Generate answer

### For Documents:
1. **Load** â†’ Extract text from PDF/PPTX
2. **Chunk** â†’ Split by sentences/semantics
3. **Embed** â†’ Convert to vectors
4. **Index** â†’ Store in vector database
5. **Query** â†’ Retrieve â†’ Generate answer

## ğŸ› Troubleshooting

### FFmpeg Not Found
```bash
# Windows (using Chocolatey)
choco install ffmpeg

# Or download from: https://ffmpeg.org/
```

### Out of Memory
- Use smaller models (Qwen 0.6B, MiniLM L6)
- Reduce FPS for video processing
- Use CPU instead of GPU

### Slow Processing
- Use smaller Whisper model (`tiny` instead of `base`)
- Reduce FPS for frame extraction
- Use FAISS instead of ChromaDB

### Video Download Fails
```bash
# Update yt-dlp
pip install --upgrade yt-dlp
```

## ğŸ“– Documentation

For detailed architecture and development guidelines, see [CLAUDE.md](CLAUDE.md)

## ğŸ™ Acknowledgments

Built with:
- [Whisper](https://github.com/openai/whisper) - OpenAI's speech recognition
- [EasyOCR](https://github.com/JaidedAI/EasyOCR) - Text detection
- [FAISS](https://github.com/facebookresearch/faiss) - Facebook's vector search
- [HuggingFace Transformers](https://huggingface.co/transformers) - NLP models
- [Streamlit](https://streamlit.io/) - Web framework

## ğŸ“„ License

This project is for educational purposes.

---

**Made with â¤ï¸ for intelligent document and video understanding**
